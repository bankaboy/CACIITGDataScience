{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up default plotting parameters\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
    "plt.rcParams.update({'font.size': 22,})\n",
    "\n",
    "sns.set_palette('viridis')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk', font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train Shape: ', (250, 302))\n",
      "('Test Shape: ', (19750, 301))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.067</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.271</td>\n",
       "      <td>1.716</td>\n",
       "      <td>1.096</td>\n",
       "      <td>1.731</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>1.904</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.856</td>\n",
       "      <td>-1.506</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-1.932</td>\n",
       "      <td>-0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1.390</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>0.317</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.311</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.189</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370</td>\n",
       "      <td>1.093</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-1.081</td>\n",
       "      <td>0.805</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-1.509</td>\n",
       "      <td>0.522</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>1.249</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>1.751</td>\n",
       "      <td>1.442</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...  \\\n",
       "0   0     1.0 -1.067 -1.114 -0.616  0.376  1.090  0.467 -0.422  0.460  ...   \n",
       "1   1     0.0 -0.831  0.271  1.716  1.096  1.731 -0.197  1.904 -0.265  ...   \n",
       "2   2     0.0  0.099  1.390 -0.732 -1.065  0.005 -0.081 -1.450  0.317  ...   \n",
       "3   3     1.0 -0.989 -0.916 -1.343  0.145  0.543  0.636  1.127  0.189  ...   \n",
       "4   4     0.0  0.811 -1.509  0.522 -0.360 -0.220 -0.959  0.334 -0.566  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.220 -0.339  0.254 -0.179  0.352  0.125  0.347  0.436  0.958 -0.824  \n",
       "1 -0.765 -0.735 -1.158  2.554  0.856 -1.506  0.462 -0.029 -1.932 -0.343  \n",
       "2 -1.311  0.799 -1.001  1.544  0.575 -0.309 -0.339 -0.148 -0.646  0.725  \n",
       "3 -1.370  1.093  0.596 -0.589 -0.649 -0.163 -0.958 -1.081  0.805  3.401  \n",
       "4 -0.178  0.718 -1.017  1.249 -0.596 -0.445  1.751  1.442 -0.393 -0.643  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('Train Shape: ', train.shape)\n",
    "print('Test Shape: ', test.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for modeling\n",
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "\n",
    "# scaling data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "ridge = linear_model.Ridge()\n",
    "lasso = linear_model.Lasso()\n",
    "elastic = linear_model.ElasticNet()\n",
    "lasso_lars = linear_model.LassoLars()\n",
    "bayesian_ridge = linear_model.BayesianRidge()\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear')\n",
    "sgd = linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ridge, lasso, elastic, lasso_lars, bayesian_ridge, logistic, sgd]\n",
    "# function to get cross validation scores\n",
    "def get_cv_scores(model):\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    print('CV Mean: ', np.mean(scores))\n",
    "    print('STD: ', np.std(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "('CV Mean: ', 0.655320621373253)\n",
      "('STD: ', 0.08822973705933819)\n",
      "\n",
      "\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "('CV Mean: ', 0.5)\n",
      "('STD: ', 0.0)\n",
      "\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "('CV Mean: ', 0.5)\n",
      "('STD: ', 0.0)\n",
      "\n",
      "\n",
      "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
      "     positive=False, precompute='auto', verbose=False)\n",
      "('CV Mean: ', 0.5)\n",
      "('STD: ', 0.0)\n",
      "\n",
      "\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "('CV Mean: ', 0.650692623797887)\n",
      "('STD: ', 0.08414499773131635)\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "('CV Mean: ', 0.6885638385638385)\n",
      "('STD: ', 0.07692541817678993)\n",
      "\n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "('CV Mean: ', 0.681066231066231)\n",
      "('STD: ', 0.09627176603868137)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through list of models\n",
    "for model in models:\n",
    "    print(model)\n",
    "    get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression and Grid Search\n",
    "Grid search is an exhaustive search over specified parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 377 out of 384 | elapsed:   17.4s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score: ', 0.7269642972850385)\n",
      "('Best Params: ', {'penalty': 'l1', 'C': 0.1, 'solver': 'saga', 'class_weight': {0: 0.6, 1: 0.4}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   17.9s finished\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_grid = dict(penalty=penalty,\n",
    "                  C=C,\n",
    "                  class_weight=class_weight,\n",
    "                  solver=solver)\n",
    "\n",
    "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CV Mean: ', 0.7013431013431013)\n",
      "('STD: ', 0.06559048891024649)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression(C=1, class_weight={1:0.6, 0:0.4}, penalty='l1', solver='liblinear')\n",
    "get_cv_scores(logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent and Random Search\n",
    "Random search is a random (obviously) search over specified parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 689 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1689 tasks      | elapsed:   23.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score: ', 0.7303431607594116)\n",
      "('Best Params: ', {'loss': 'perceptron', 'eta0': 10, 'learning_rate': 'optimal', 'penalty': 'l1', 'alpha': 0.01, 'class_weight': {0: 0.3, 1: 0.7}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2993 out of 3000 | elapsed:   39.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:   39.3s finished\n"
     ]
    }
   ],
   "source": [
    "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "eta0 = [1, 10, 100]\n",
    "\n",
    "param_distributions = dict(loss=loss,\n",
    "                           penalty=penalty,\n",
    "                           alpha=alpha,\n",
    "                           learning_rate=learning_rate,\n",
    "                           class_weight=class_weight,\n",
    "                           eta0=eta0)\n",
    "\n",
    "random = RandomizedSearchCV(estimator=sgd, param_distributions=param_distributions, scoring='roc_auc', verbose=1, n_jobs=-1, n_iter=1000)\n",
    "random_result = random.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', random_result.best_score_)\n",
    "print('Best Params: ', random_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CV Mean: ', 0.7325545325545326)\n",
      "('STD: ', 0.09729936666075499)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(alpha=0.1,\n",
    "                                 class_weight={1:0.7, 0:0.3},\n",
    "                                 eta0=100,\n",
    "                                 learning_rate='optimal',\n",
    "                                 loss='log',\n",
    "                                 penalty='elasticnet')\n",
    "get_cv_scores(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sgd.fit(X_train, y_train).predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
